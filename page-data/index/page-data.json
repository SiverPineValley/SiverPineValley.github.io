{"componentChunkName":"component---src-pages-index-js","path":"/","result":{"data":{"site":{"siteMetadata":{"title":"Devlog","configs":{"countOfInitialPost":10}}},"allMarkdownRemark":{"edges":[{"node":{"excerpt":"이번에는 2차원 배열에서 구간 합을 구하는 문제이다. 2차원이다 보니 아무래도 1차원 배열보다는 수식이 복잡할 수 밖에 없지만, 1차원 배열에서 사용한 수식을 사용한다면 그리 어렵지 않게 구현할 수 있다. 1. 합 배열 구하기 1 2 3 4 2 3 4 5 3 4 5 6 4 5 6 7 문제에서 제시한 예시인데, 먼저 합 배열을 구해야 한다. 2차원 배열이다…","fields":{"slug":"/Algorithm/[백준] [리스트] [11660] 구간 합 구하기 5/"},"frontmatter":{"date":"January 02, 2026","title":"[백준] [리스트] [11660] 구간 합 구하기 5","category":"Algorithm","draft":false}}},{"node":{"excerpt":"리스트를 활용하는 또 다른 방법에는 구간 합이 있다. 리스트를 메모리처럼 활용하는 방법인데, 각 숫자 배열을 입력받을 때 특정 구간까지의 합도 계산해두는 방법이다. 시간 복잡도는 배열을 한 번 순회하는 정도이므로 O(N)이고, 이렇게 합 배열을 만들어두면, 특정 구간 합을 구할 때는 O(1)으로 계산이 가능하다. 먼저, 합 배열 S는 다음과 같이 정의 가…","fields":{"slug":"/Algorithm/[백준] [리스트] [11659] 구간 합 구하기 4/"},"frontmatter":{"date":"January 02, 2026","title":"[백준] [리스트] [11659] 구간 합 구하기 4","category":"Algorithm","draft":false}}},{"node":{"excerpt":"알고리즘을 다시 공부하기 시작했다. 그간 BE 소양을 기르기 위해 다양한 공부를 해왔었는데, k8s부터 퍼블릭 클라우드, Kafka, Grafana, gRPC 등등 업무와 관련된 스킬들을 업그레이드해왔었다. 실제로 업무에 도움도 많이 되었었고, 요즘 BE에서 요구되는 지식들을 많이 익히기도 했지만 내 업무에 대한 싫증이 생겼던 것 같다. 이제는… 이직을 …","fields":{"slug":"/Algorithm/[백준] [리스트] [1546] 평균 구하기/"},"frontmatter":{"date":"January 02, 2026","title":"[백준] [리스트] [1546] 평균 구하기","category":"Algorithm","draft":false}}},{"node":{"excerpt":"1-2-1) IAM Policy 분류 권한을 제한하는 정책 (Guardrail) 조직 SCP 정책 (Organization SCPs) 권한 경계 정책 (Permissions boundaries) 세션 정책 (Session policies) 권한을 부여하는 정책 (Grant) 자격증명 기반 정책 (Identity-based Policies) AWS 관리형 …","fields":{"slug":"/aws/aws_1_2/"},"frontmatter":{"date":"August 23, 2025","title":"1-2) IAM Policy","category":"aws","draft":false}}},{"node":{"excerpt":"모범 사례를 기반으로 안전하고 규정 준수에 적합한 \b다중 계정 AWS 환경을 손쉽게 설정하고 관리할 수 있는 방법 계정 생성을 위해 AWS Organization을 사용한다. 장점 몇 번의 클릭으로 손쉽게 환경 설정 가능 을 사용하여 동작중인 정책 자동화 정책 위반 감지와 수정 상호작용 대시보드를 통한 컴플라이언스 모니터링 1-12-1) AWS Contr…","fields":{"slug":"/aws/aws_1_12/"},"frontmatter":{"date":"June 15, 2025","title":"1-12) AWS Control Tower","category":"aws","draft":false}}},{"node":{"excerpt":"1-11-0) What is Microsoft Active Directory (AD) AD 도메인 서비스를 사용하는 어떠한 Windows Server에서도 찾아볼 수 있다. 오브젝트들의 데이터베이스: 유저 계정, 컴퓨터, 프린터, 파일 공유, 보안 그룹등을 저장 중앙화된 보안 관리, 계정 생성, 권한 부여 오브젝트들은 트리로 조직된다. 트리들의 그룹은 숲…","fields":{"slug":"/aws/aws_1_11/"},"frontmatter":{"date":"June 15, 2025","title":"1-11) AWS Active Directory (AD)","category":"aws","draft":false}}},{"node":{"excerpt":"한 번의 로그인 (Single Sign-On)으로 다음 서비스들에 자동으로 로그인 연동을 제공 AWS accounts in AWS Organizations Business cloud applications (Salesforce, Box, Microsoft 365) SAML2.0-enabled applications EC2 Windows Instances …","fields":{"slug":"/aws/aws_1_10/"},"frontmatter":{"date":"June 15, 2025","title":"1-10) AWS IAM Identity Center (AWS Single Sign-On)","category":"aws","draft":false}}},{"node":{"excerpt":"는 유저와 역할을 지원한다. (not groups) IAM 엔티티가 가질 수 있는 최대 권한의 범위를 설정하는 규칙을 관리하기 위해 사용되는 발전된 기능. 아래와 같은 Permission Boundaries와 IAM Policy를 갖는 경우, 유저 생성 권한을 갖더라도 권한 범위가 s3, cloudwatch, ec2이므로 실제 행사할 수 있는 권한은 아무…","fields":{"slug":"/aws/aws_1_9/"},"frontmatter":{"date":"June 15, 2025","title":"1-9) IAM Permission Boundaries","category":"aws","draft":false}}},{"node":{"excerpt":"1-8-0) AWS Policy Conditions 1-8-1) IAM for S3 s3:ListBucket 권한은  -> 특정 서비스에 적용되므로 arn이 S3의 arn으로 적용됨 버킷 레벨 권한 s3:GetObject,s3:PutObject,s3:DeleteObject 는 에 적용됨. 객체 레벨 권한 1-8-2) Resouce Policies AWS …","fields":{"slug":"/aws/aws_1_8/"},"frontmatter":{"date":"June 08, 2025","title":"1-8) IAM 고급","category":"aws","draft":false}}},{"node":{"excerpt":"1-7-1) AWS Organizations 글로벌 서비스 여러 개의 AWS 계정들을 관리하는 것을 허용한다. 메인 계정은 관리용 계정이고, 다른 계정들은 멤버 계정들이다. 멤버 계정들은 하나의 조직의 일부만 될 수 있다. 모든 계정에 대한 통합 청구된다. 모든 사용량을 취합하기 때문에 가격 정책에 이점이 있다. 전체 계정에 대한 공유된 예약 자원들과 가…","fields":{"slug":"/aws/aws_1_7/"},"frontmatter":{"date":"June 08, 2025","title":"1-7) AWS Organizations","category":"aws","draft":false}}},{"node":{"excerpt":"2-4-1) EC2 인스턴스 역할 EC2 인스턴스에 IAM의 역할을 매핑하여 사용할 수 있다. 인스턴스 > 작업 > 보안 > IAM 역할 수정을 통해 인스턴스의 IAM 역할을 수정할 수 있다. 2-4-2) EC2 인스턴스 비용 플랜 • On-Demand Instances: 짧은 워크로드, 예측 가능한 가격, 초당 사용량 기준 가격 책정됨\n• Reserve…","fields":{"slug":"/aws/aws_2_4/"},"frontmatter":{"date":"February 24, 2025","title":"2-4) EC2 인스턴스","category":"aws","draft":false}}},{"node":{"excerpt":"네트워크 및 보안 > 보안 그룹 Security Group은 AWS의 네트워크 보안의 근간이다. EC2 인스턴스의 인바운드/아웃바운드되는 트래픽을 제어한다. Security Group은 화이트리스트 방식으로, 허용되는 정책만 적용 가능하다. 즉, EC2 인스턴스의 방화벽 역할을 한다. Security Group은 Stateful한 방식으로, 요청의 응답에…","fields":{"slug":"/aws/aws_2_3/"},"frontmatter":{"date":"February 24, 2025","title":"2-3) Security Groups","category":"aws","draft":false}}},{"node":{"excerpt":"과금 정보 및 비용 관리 > 계정에서 IAM 유저 계정 별 과금 정보 및 비용 관리 서비스에 접근 가능 여부를 설정할 수 있다. 과금 정보 및 비용 관리 > 프리 티어에서 프리 티어의 기준을 넘어서 사용중인지 확인할 수 있다 과금 정보 및 비용 관리 > 예산을 통해 특정 예산이 초과하는 경우 알람을 보내도록 할 수 있다.","fields":{"slug":"/aws/aws_2_1/"},"frontmatter":{"date":"February 10, 2025","title":"2-1) AWS 예산 설정","category":"aws","draft":false}}},{"node":{"excerpt":"EC2(Elastic Compute Cloud)는 AWS에서 제공하는 가장 인기있는 서비스 중 하나로, 여러 가지 자원 및 서비스를 제공한다. 가상 머신 빌려주기 (EC2) 가상 드라이브에 데이터 저장 (EBS) 여러 머신에 부하 분산 (ELB) 오토 스케일링 그룹을 사용하여 서비스 스케일링 (ASG) EC2의 사이징 & 설정 옵션들은 다음과 같다. OS…","fields":{"slug":"/aws/aws_2_2/"},"frontmatter":{"date":"February 10, 2025","title":"2-2) EC2 (Elastic Compute Cloud)","category":"aws","draft":false}}},{"node":{"excerpt":"IAM Credential Report (IAM 자격증명 보고서) (계정레벨) Root 계정의 유저들을 리스트업하고 그들의 다양한 자격증명 상태를 나열하는 자격 증명 보고서를 생성하고 다운로드할 수 있다. 이 보고서를 통해 암호, 액세스 키 업데이트 등 보안 인증 수명 주기 요구 사항이 어떤 영향을 주는지 감사할 수 있다. 외부 감사자에게 이 보고서를 제…","fields":{"slug":"/aws/aws_1_6/"},"frontmatter":{"date":"February 09, 2025","title":"1-6) AWS Security Tools","category":"aws","draft":false}}},{"node":{"excerpt":"\b은 와 여러 면에서 유사하다. Policy를 통해서 특정 권한을 할 수 있거나 할 수 없도록 하는 자격 증명을 가진다. Policy는 이러한 자격 증명을 사용자 / 사용자 그룹 / 역할에 부여가 가능한데, 역할은 한 사람과 연관되지 않고 해당 역할이 필요한 사람이라면 누구든지 맡을 수 있다. 또한 역할에는 그와 연관된 암호 또는 액세스 키와 같은 표준 …","fields":{"slug":"/aws/aws_1_5/"},"frontmatter":{"date":"February 09, 2025","title":"1-5) IAM Role & STS","category":"aws","draft":false}}},{"node":{"excerpt":"AWS 계정의 보안을 위해서는 크게 두 가지 방법을 활용할 수 있다. 패스워드 정책 (계정 설정 - 암호 정책) 최소 패스워드 길이 특정 문자 타입 필수 설정 대/소문자, 숫자, 특수문자 IAM 유저들에게 패스워드를 바꿀 수 있고 특정 기간마다 변경되도록 설정 이전에 사용했던 패스워드 사용하지 못하도록 설정 IAM MFA (보안 자격 증명 - 멀티 팩터 …","fields":{"slug":"/aws/aws_1_3/"},"frontmatter":{"date":"February 09, 2025","title":"1-3) IAM MFA","category":"aws","draft":false}}},{"node":{"excerpt":"AWS에 접속하기 위해서는 세 가지 옵션이 존재한다. AWS Management Console (패스워드 + MFA) AWS Command Line Interface (CLI): 로컬 컴퓨터의 콘솔에서 사용하는 명령어 기반의 CLI (Access Key에 의해 보호됨) AWS Software Developer Key (SDK): 애플리케이션 코드에서 AP…","fields":{"slug":"/aws/aws_1_4/"},"frontmatter":{"date":"February 09, 2025","title":"1-4) AWS Access Key, CLI, SDK","category":"aws","draft":false}}},{"node":{"excerpt":"1-1-1) Users & Group 은 사용자를 생성하고 그룹에 배치하여 권한을 조정할 수 있는 글로벌 서비스이다. 은 기본적으로 생성되며, 오직 계정을 생성할 때만 사용되어야 하며 공유되어서도 안된다. 는 조직 내에서 사용되는 한 사람의 계정을 의미하며 으로 묶일 수 있다. 그룹에 묶이지 않아도 상관은 없고, 여러 그룹에 동시에 존재할 수도 있다. 은…","fields":{"slug":"/aws/aws_1_1/"},"frontmatter":{"date":"February 05, 2025","title":"1-1) IAM User & Group & Policy 개요","category":"aws","draft":false}}},{"node":{"excerpt":"9-7-1) 분산 모드 카프카 커넥트 설정 9-7-2) 분산 모드 카프카 커넥트 실행, 플러그인 확인 9-7-3) FileStreamSinkConnector 테스트 9-7-4) FileStreamSinkConnector 실행 확인 커넥터의 위치, 실행 위치, 커넥터의 종류 (source, sink)를 확인할 수 있다. 9-7-5) FileStreamSin…","fields":{"slug":"/kafka/kafka_9_7/"},"frontmatter":{"date":"January 29, 2025","title":"9-7) 분산 모드 카프카 커넥트 실습","category":"kafka","draft":false}}},{"node":{"excerpt":"싱크 커넥터는 토픽의 데이터를 타깃 애플리케이션 또는 타깃 파일로 저장하는 역할을 한다. (컨슈머의 동작 방식과 유사하다.) 카프카 커넥트 라이브러리에서 제공하는 와  클래스를 사용하면 직접 싱크 커넥터를 구현할 수 있다. 직접 구현한 싱크 커넥트는 빌드하여 jar로 만들고 커넥트의 플러그인으로 추가하여 사용할 수 있다. SinkConnector Sink…","fields":{"slug":"/kafka/kafka_9_6/"},"frontmatter":{"date":"January 29, 2025","title":"9-6) 카프카 싱크 커넥터","category":"kafka","draft":false}}},{"node":{"excerpt":"소스 커넥터는 소스 애플리케이션 또는 소스 파일로부터 데이터를 가져와 토픽으로 넣는 역할을 한다. 오픈소스 소스 커넥터를 사용해도 되지만 라이센스 문제나 로직이 원하는 요구사항과 맞지 않아서 ㅈ기접 개발해야 하는 경우도 있는데, 이때는 카프카 커넥트 라이브러리에서 제공하는 와  클래스를 사용하여 직접 커넥터를 구현하면 된다. 직접 구현한 커넥터를 빌드하여…","fields":{"slug":"/kafka/kafka_9_5/"},"frontmatter":{"date":"January 29, 2025","title":"9-5) 커스텀 소스 커넥터","category":"kafka","draft":false}}},{"node":{"excerpt":"분산 모드 커넥트는 2개 이상의 프로세스가 1개의 그룹으로 묶여서 운영된다. 이를 통해 1개의 커넥트 프로세스에 이슈가 발생하여 종료되더라도 살아 있는 나머지 1개 커넥트 프로세스가 커넥터를 이어받아 파이프라인을 지속적으로 실행할 수 있다는 특징이 있다. 9-4-1) 분산 모드 커넥트 설정 분산 모드 커넥트를 실행하기 위해서는  파일을 수정해야 한다. 커…","fields":{"slug":"/kafka/kafka_9_4/"},"frontmatter":{"date":"January 29, 2025","title":"9-4) 분산 모드 커넥트 (Distributed Mode Kafka Connect)","category":"kafka","draft":false}}},{"node":{"excerpt":"9-3-1) 단일 모드 커넥트 설정 단일 모드 커넥트를 실행하기 위해서는 단일 모드 커넥트를 참조하는 파일인  파일을 수정해야 한다. 단일 모드 커넥트로 실행 시 파라미터로 커넥트 설정파일과 커넥터 설정파일을 차례로 넣어 실행하면 된다. 다음은 커넥터의 설정 파일(connect-file-source.properties)이다.","fields":{"slug":"/kafka/kafka_9_3/"},"frontmatter":{"date":"January 28, 2025","title":"9-3) 단일 모드 커넥트 (Single Mode Kafka Connect)","category":"kafka","draft":false}}},{"node":{"excerpt":"카프카 커넥트를 실행하는 방법에는 두 가지 방법이 있다. 단일 모드 커넥트(Standalone Mode Kafka Connect): 단일 애플리케이션으로 실행된다. 커넥트를 정의하는 파일을 작성하고 해당 파일을 실행하는 단일 모드 커넥트를 실행하여 파이프라인을 생성할 수 있다.\n분산 모드 커넥트(Distributed Mode Kafka Connect) 9…","fields":{"slug":"/kafka/kafka_9_2/"},"frontmatter":{"date":"January 28, 2025","title":"9-2) 카프카 커넥트 배포 및 운영","category":"kafka","draft":false}}},{"node":{"excerpt":"9-1-1) 카프카 커넥터 소개 카프카 커넥터는 카프카 오픈소스에 포함된 툴 중 하나로 데이터 파이프라인 생성 시 반복 작업을 줄이고 효율적인 전송을 이루기 위한 애플리케이션이다. 커넥트는 특정한 작업 형태를 템플릿으로 만들어놓은 커넥터를 실행함으로써 반복 작업을 줄일 수 있다. 사용자가 커넥트에 커넥터 생성 명령을 내리면 커넥트는 내부에 커넥터와 태스크…","fields":{"slug":"/kafka/kafka_9_1/"},"frontmatter":{"date":"January 28, 2025","title":"9-1) 카프카 커넥터","category":"kafka","draft":false}}},{"node":{"excerpt":"프로세서 API는 스트림즈 DSL보다는 투박한 코드를 가지지만 토폴로지를 기준으로 데이터를 처리한다는 관점에서는 동일한 역할을 한다. 스트림즈 DSL은 데이터 처리, 분기, 조인을 위해 다양한 메서드들을 제공하지만 추가적인 상세 로직의 구현이 필요하다면\b프로세서 API를 활용할 수 있다. 프로세서 API에서는 스트림즈 DSL에서 사용했던 KStream, …","fields":{"slug":"/kafka/kafka_8_7/"},"frontmatter":{"date":"January 27, 2025","title":"8-7) 프로세서 API","category":"kafka","draft":false}}},{"node":{"excerpt":"카프카 스트림즈에서 KTable은 카프카 토픽의 데이터를 로컬의 rocksDB에 Materialized View로 만들어 두고 사용하기 때문에 레코드의 메시지 키, 메시지 값을 기반으로 KeyValueStore로 사용할 수 있다. 특정 토픽을 KTable로 사용하고 ReadOnlyKeyValueStore로 뷰를 가져오면 메시지 키를 기반으로 토픽 데이터를…","fields":{"slug":"/kafka/kafka_8_6/"},"frontmatter":{"date":"January 27, 2025","title":"8-6) 스트림즈 DSL - Queryable store","category":"kafka","draft":false}}},{"node":{"excerpt":"스트림 데이터를 분석할 때 가장 많이 활용하는 프로세싱 중 하나는 윈도우 연산이다. 윈도우 연산은 특정 시간에 대응하여 취합 연산을 처리할 때 사용한다. 카프카 스트림즈에서 제공하는 윈도우 프로세싱은 다음과 같이 4가지를 제공한다. 모든 프로세싱은 메시지 키를 기준으로 취합되므로, 해당 토픽에 동일한 파티션에는 동일한 메시지 키가 있는 레코드가 존재해야지…","fields":{"slug":"/kafka/kafka_8_5/"},"frontmatter":{"date":"January 27, 2025","title":"8-5) 스트림즈 DSL의 윈도우 프로세싱","category":"kafka","draft":false}}},{"node":{"excerpt":"8-4-1)  스트림즈 애플리케이션 - 필터 : 파라미터로 들어온 토픽의 데이터를 KSteram 구조체로 가져오기 위한 소스 프로세서. : 파라미터로 들어온 필터링 메서드를 사용하여 특정 메시지 값을 필터링하기 위해 사용. : 특정 토픽으로 DSL을 적용한 레코드를 저장한다. 8-4-2) KTable과 KStrem을 join() KTable과 KStrea…","fields":{"slug":"/kafka/kafka_8_4/"},"frontmatter":{"date":"January 27, 2025","title":"8-4) 스트림즈 애플리케이션 개발하기","category":"kafka","draft":false}}},{"node":{"excerpt":"8-3-1) 필수 옵션 : 프로듀서가 데이터를 전송할 대상 카프카 클러스터에 속한 브로커의 호스트 이름 : 포트를 1개 이상 작성한다. : 스트림즈 애플리케이션을 구분하기 위한 고유한 아이디를 설정한다. 다른 로직을 가진 스트림즈 애플리케이션들은 모두 다른 ID를 가져야 한다. 8-3-2) 선택 옵션 : 레코드의 메시지 키를 직렬화, 역직렬화하는 클래스를…","fields":{"slug":"/kafka/kafka_8_3/"},"frontmatter":{"date":"January 27, 2025","title":"8-3) 스트림즈DSL 중요 옵션(필수 옵션)","category":"kafka","draft":false}}},{"node":{"excerpt":"8-2-1) KStream 은 레코드의 흐름을 표현한 것으로 메시지 키와 메시지 값으로 구성되어 있다. KStream으로 데이터를 조회하면 토픽에 존재하는(또는 KStream에 존재하는) 모든 레코드가 출력된다. 컨슈머로 토픽을 구독하는 것과 동일하다고 볼 수 있다. 8-2-2) KTable 은 KStream과 다르게 메시지 키를 기준으로 묶어서 사용한다…","fields":{"slug":"/kafka/kafka_8_2/"},"frontmatter":{"date":"January 21, 2025","title":"8-2) KStream, KTable, GlobalKTable","category":"kafka","draft":false}}},{"node":{"excerpt":"8-1-1) 카프카 스트림즈 카프카 스트림즈는 토픽에 적재된 데이터를 실시간으로 변환하여 다른 토픽에 적재하는 라이브러리이다. 스트림즈는 카프카에서 공식적으로 지원하는 라이브러리이다. 매번 카프카 버전이 오를 때마다 스트림즈 자바 라이브러리도 같이 릴리즈된다. 그렇기 때문에 자바 기반 스트림즈 애플리케이션은 카프카 클러스터와 완벽하게 호환되면서 스트림 처…","fields":{"slug":"/kafka/kafka_8_1/"},"frontmatter":{"date":"January 21, 2025","title":"8-1) 카프카 스트림즈","category":"kafka","draft":false}}},{"node":{"excerpt":"7-2-1) 트랜잭션 프로듀서 카프카에서 트랜잭션은 다수의 파티션에 데이터를 저장할 경우 모든 데이터에 대해서 동일한 을 만족시키기 위해 사용된다. 원자성을 만족시킨다는 의미는 다수의 데이터를 동일 트랜잭션으로 묶음으로써 전체 데이터를 처리하거나 전체 데이터를 처리하지 않도록 함을 의미한다. 트랜잭션 프로듀서는 사용자가 보낸 데이터를 레코드로 파티션에 저…","fields":{"slug":"/kafka/kafka_7_2/"},"frontmatter":{"date":"January 13, 2025","title":"7-2) 트랜잭션 프로듀서, 컨슈머","category":"kafka","draft":false}}},{"node":{"excerpt":"멱등성이란 여러 번 연산을 하더라도 동일한 결과를 나타내는 것을 의미한다. 이러한 의미에서 멱등성 프로듀서는 동일한 데이터를 여러 번 전송하더라도 카프카 클러스터에는 단 한 번만 저장됨을 의미한다. 기본 프로듀서의 동작 방식은 적어도 한번 전달 (at least once delivery)을 지원한다. 적어도 한번 전달이란 프로듀서가 클러스터에 데이터를 전…","fields":{"slug":"/kafka/kafka_7_1/"},"frontmatter":{"date":"January 13, 2025","title":"7-1) 멱등성 프로듀서","category":"kafka","draft":false}}},{"node":{"excerpt":"6-4-1) 카프카 버로우 버로우는 링크드인에서 개발하여 오픈소스로 공개한 컨슈머 랙 체크 툴로서 RestAPI를 통해 컨슈머 그룹 별로 컨슈머 랙을 확인할 수 있다. 외부 모니터링 툴을 사용하면 카프카 클러스터에 포함된 모든 컨슈머, 토픽들의 랙 정보를 한번에 모니터링할 수 있다는 장점이 있다. 또한, 모니터링 툴들은 클러스터와 연동되어 컨슈머의 데이터…","fields":{"slug":"/kafka/kafka_6_4/"},"frontmatter":{"date":"January 11, 2025","title":"6-4) 버로우","category":"kafka","draft":false}}},{"node":{"excerpt":"6-3-1) 컨슈머 랙 컨슈머 랙(Lag)은 파티션의 최신 오프셋과 컨슈머 오프셋간의 차이이다. 프로듀서는 계속해서 새로운 레코드를 파티션에 저장하고, 컨슈머는 처리할 수 있는 만큼 데이터를 가져간다. 컨슈머 랙은 컨슈머가 정상적으로 동작하는지 여부를 확인할 수 있기 때문에 컨슈머 애플리케이션을 운영하면 필수적으로 모니터링해야 하는 요소이다. 컨슈머 랙은…","fields":{"slug":"/kafka/kafka_6_3/"},"frontmatter":{"date":"January 11, 2025","title":"6-3) 컨슈머 랙","category":"kafka","draft":false}}},{"node":{"excerpt":"6-2-1) java를 이용한 컨슈머 애플리케이션 개발 각 토픽을 컨슘하기 위해서는 를 통해서 구독할 수 있다. 이후, 무한 루프 내에서  메소드를 사용하여 주기적으로 메시지를 가져올 수 있다. 여기서  메소드를 너무 오래 사용하게 되면 리밸런싱이 발생하므로 주의하여야 한다. 6-2-2) 수동 커밋 컨슈머 애플리케이션 6-2-2-1) 동기 커밋 컨슈머 수…","fields":{"slug":"/kafka/kafka_6_2/"},"frontmatter":{"date":"January 11, 2025","title":"6-2) 컨슈머 애플리케이션 개발","category":"kafka","draft":false}}},{"node":{"excerpt":"6-1-1) 카프카 컨슈머 소개 카프카 프로듀서가 전송한 데이터는 카프카 브로커에 적재된다. 컨슈머에 적재된 데이터를 사용하기 위해 브로커로부터 데이터를 가져와서 필요한 처리를 한다. 6-1-2) 컨슈머 내부 구조 (Java 라이브러리) Fetcher: 리더 파티션으로 부터 데이터를 미리 가져와서 대기 poll(): Fetcher에 있는 레코드들을 리턴하…","fields":{"slug":"/kafka/kafka_6_1/"},"frontmatter":{"date":"January 11, 2025","title":"6-1) 컨슈머","category":"kafka","draft":false}}},{"node":{"excerpt":"5-2-1) java를 이용한 프로듀서 애플리케이션 개발  을 통해 프로듀서의 필수 설정(bootstrap_servers)을 설정한다.  객체 생성 후  함수를 통해 record를 프로듀스 할 수 있다.  함수는 배치를 강제로 전송하는 함수이고, 는 프로듀서와의 연결을 종료한다. 5-2-2) 메시지 키가 존재하는 레코드 프로듀스 를 통해 레코드 생성 시 …","fields":{"slug":"/kafka/kafka_5_2/"},"frontmatter":{"date":"January 11, 2025","title":"5-2) 프로듀서 애플리케이션 개발","category":"kafka","draft":false}}},{"node":{"excerpt":"5-1-1) 카프카 프로듀서 소개 카프카의 데이터 시작점은 프로듀서이다. 프로듀서 애플리케이션은 카프카에 필요한 데이터를 선언하고 특정 토픽의 파티션에 데이터를 전송한다. 프로듀서는 데이터를 전송할 때 리더 파티션을 가지고 있는 카프카 프로듀서와 직접 통신한다. 프로듀서는 카프카 브로커로 데이터를 전송할 때 내부적으로 파티셔너, 배치 단계를 거친다. 5-…","fields":{"slug":"/kafka/kafka_5_1/"},"frontmatter":{"date":"January 06, 2025","title":"5-1) 프로듀서","category":"kafka","draft":false}}},{"node":{"excerpt":"Kafka에서 토픽을 생성하는 방법에는 두 가지 방법이 있다. 첫 번째로 kafka-topics.sh 와 같은 CLI툴을 사용하여 명시적으로 생성하는 방법이다. 토픽을 효과적으로 유지보수하기 위해 추천되는 방법이다. 두 번 째로는 컨슈머나 프로듀서가 카프카 브로커에 생성되지 않은 토픽에 대한 데이터를 요청할 때이다. 두 번째 방법에 대한 옵션이 바로  이…","fields":{"slug":"/kafka/kafka_4_2/"},"frontmatter":{"date":"December 23, 2024","title":"4-2) 토픽을 생성하는 두 가지 방법","category":"kafka","draft":false}}},{"node":{"excerpt":"Kafka CLI: 카프카를 운영할 때 가장 많이 접하는 도구로, 카프카 브로커 운영에 필요한 다양한 명령을 내릴 수 있다. 카프카 클라이언트 애플리케이션을 운영할 때는 카프카 클러스터와 연동하여 데이터를 주고받는 것도 중요하지만 토픽이나 파티션 변경과 같은 명령을 실행할 경우도 많이 발생한다. 그렇기 때문에 카프카 커맨드 라인 툴과 각 툴별 옵션에 대해…","fields":{"slug":"/kafka/kafka_4_1/"},"frontmatter":{"date":"December 23, 2024","title":"4-1) 카프카 CLI 툴 소개","category":"kafka","draft":false}}},{"node":{"excerpt":"3-3-1) 장점 인프라 관리의 효율화: Kafka 클러스터는 최소 3대 이상의 서버로 운영되는데, 클러스터 담당자의 입장에서는 이러한 모든 서버를 운영하고 관리해야 하는데, Saas는 이러한 운영 burden의 많은 부분을 해소해준다. 서버 상태를 모니터링하다가 장애가 발생하면 바로 정상 서버로 대체해주거나, 쉽게 스케일업 / 스케일다운을 진행할 수 있…","fields":{"slug":"/kafka/kafka_3_3/"},"frontmatter":{"date":"December 07, 2024","title":"3-3) Saas형 Apache Kafka 장점과 단점","category":"kafka","draft":false}}},{"node":{"excerpt":"","fields":{"slug":"/kafka/kafka_3_2/"},"frontmatter":{"date":"December 07, 2024","title":"3-2) Saas형 Apache Kafka 소개","category":"kafka","draft":false}}},{"node":{"excerpt":"기업용 Kafka는 Confluent Platform으로, 여러 부분에서 튜닝된 기능들이 제공된다. 더 나은 커넥터 기능들을 제공한다. 또한, 모니터링 툴(felice)도 제공된다.","fields":{"slug":"/kafka/kafka_3_1/"},"frontmatter":{"date":"December 07, 2024","title":"3-1) Kafka 클러스터를 운영하는 여러 가지 방법","category":"kafka","draft":false}}},{"node":{"excerpt":"카프카 클라이언트는 통신하고자 하는 를 알기 위해 데이터를 주고 (프로듀서) 받기 (컨슈머) 전에 메타데이터를 브로커로부터 전달받는다. 메타데이터는 다음과 같은 옵션을 통해 리프레쉬된다. : 메타데이터를 강제로 리프레쉬하는 간격. 기본값은 5분. : 프로듀서가 유휴상태일 때 메타데이터를 캐시에 유지하는 기간.  예를 들어, 프로듀서가 특정 토픽으로 데이터…","fields":{"slug":"/kafka/kafka_2_9/"},"frontmatter":{"date":"December 07, 2024","title":"2-9) 클라이언트 메타데이터와 브로커 통신","category":"kafka","draft":false}}},{"node":{"excerpt":"토픽 이름은 대/소문자, 숫자 0-9, 마침표(.), 언더바( _ ), 하이픈(-) 조합으로 생성할 수 있다. 이외의 문자열이 포함된 토픽 이름은 생성 불가하다. 토픽 이름 길이는 249자 미만이다. 내부 관리용 토픽 (comsumer_offsets, transaction_state) 로는 생성 불가능하다. 카프카 내부 로직 때문에 마침표(.)와 언더바(…","fields":{"slug":"/kafka/kafka_2_8/"},"frontmatter":{"date":"December 07, 2024","title":"2-8) 토픽 이름 제약 조건과 유지보수 하기 좋은 토픽 이름 정하기","category":"kafka","draft":false}}},{"node":{"excerpt":": 카프카에서 데이터를 구분하기 위해 사용되는 단위. 토픽은 1개 이상의 파티션을 소유한다. 파티션에는 프로듀서가 보낸 데이터가 저장되는데, 이를 라고 한다. : 자료구조에서 접하는 와 비슷한 구조로, 컨슈머는 FIFO 구조와 같이 먼저 들어간 데이터를 먼저 컨슘한다. 큐와 다른 점은 레코드가 컨슘되더라도 삭제하지 않는다는 점이다. 따라서 다양한 목적을 …","fields":{"slug":"/kafka/kafka_2_6/"},"frontmatter":{"date":"December 07, 2024","title":"2-6) 토픽과 파티션","category":"kafka","draft":false}}},{"node":{"excerpt":"레코드는 타임스탬프, 헤더, 오프셋, 메시지 키, 메시지 값으로 구성되어 있다. Producer가 생성한 레코드가 브로커로 전송되면, 타임스탬프와 오프셋이 지정된다. 브로커에 한 번 적재된 데이터는 수정 불가하고, retention 정책(용량/기간)에 의해서만 삭제될 수 있다. 레코드의 는 스트림 프로레싱에서 활용하기 위해 시간을 저장하는 용도로 사용된다…","fields":{"slug":"/kafka/kafka_2_7/"},"frontmatter":{"date":"December 07, 2024","title":"2-7) 레코드","category":"kafka","draft":false}}},{"node":{"excerpt":"은 브로커의 또 다른 역할 중 하나이다. 는 리더 파티션과 팔로워 파티션이 모두 싱크된다는 의미이다. 즉, 리더 파티션의 모든 데이터가 팔로워 파티션에 모두 복제된 상태를 의미한다. 만약, ISR로 묶이지 않은 두 개의 브로커가 존재할 때 리더 파티션의 브로커에 장애가 발생해서 리더 파티션을 팔로워 파티션이 이어 받게 된다면 특정 데이터는 유실될 수 있다…","fields":{"slug":"/kafka/kafka_2_5/"},"frontmatter":{"date":"December 07, 2024","title":"2-5) ISR (In-Sync-Replicas)","category":"kafka","draft":false}}},{"node":{"excerpt":"은 브로커의 또 다른 역할 중 하나이다. 데이터 복제는 카프카를 장애 허용 시스템 (fault tolerant system)으로 동작하게 하는 원동력이다. 복제는 클러스터로 묶인 일부에 장애가 발생하더라도, 데이터를 유실하지 않고 안전하게 사용하기 위함이다. 카프카의 데이터 복제는 파티션 단위로 이루어지는데, 토픽이 생성될 때 파티션의 복제 개수 (rep…","fields":{"slug":"/kafka/kafka_2_4/"},"frontmatter":{"date":"December 07, 2024","title":"2-4) 복제 (replication)","category":"kafka","draft":false}}},{"node":{"excerpt":"데이터의 저장은 브로커의 역할 중 하나이다. 카프카를 실행할 때 config/server.properties의  옵션에 지정한 경로에 데이터를 저장한다. (토픽 이름 + Partition 번호를 조합)\n- 해당 경로 안에는 여러 파일이 생성되는데, 에는 메시지와 메타데이터, 에는 메시지의 오프셋을 인덱싱한 파일,  파일에는 타임스탬프 값을 기준으로 인덱싱…","fields":{"slug":"/kafka/kafka_2_3/"},"frontmatter":{"date":"December 07, 2024","title":"2-3) 로그와 세그먼트","category":"kafka","draft":false}}},{"node":{"excerpt":"2-2-1) Kafka 클러스터와 브로커 는 카프카 클라이언트와 데이터를 주고받기 위해 사용하는 주체이자, 데이터를 분산 저장하여 장애 상황에서도 데이터를 안전하게 사용할 수 있도록 도와주는 애플리케이션이다. 보통 브로커는 하나의 서버에서 한개의 프로세스만 동작하는 인스턴스 단위로 이러한 브로커들이 모여 클러스터를 형성한다. 카프카 클러스터로 묶인 브로커…","fields":{"slug":"/kafka/kafka_2_2/"},"frontmatter":{"date":"December 07, 2024","title":"2-2) Kafka 클러스터와 브로커, 주키퍼","category":"kafka","draft":false}}},{"node":{"excerpt":"Kafka 클러스터는 여러 개의 브로커로 이루어져 있으며 토픽 단위로 데이터가 저장된다. 데이터의 최초 제공자는 Producer라고 하며, Consumer가 토픽을 구독하였다가 이를 받아가는 형태이다. Kafka의 모든 기능들은 Java를 기반으로 구현되었기 때문에 go, javascript와 같은 3rd 파티 언어들의 라이브러리들에서는 모든 기능이 제공…","fields":{"slug":"/kafka/kafka_2_1/"},"frontmatter":{"date":"December 07, 2024","title":"2-1) 오픈 소스 Apache Kafka 생태계","category":"kafka","draft":false}}},{"node":{"excerpt":"1-1) Apache Kafka의 특징 특징 상세 설명 높은 데이터 처리량 Kafka는 Producer가 브로커로 데이터를 보낼 때, Consumer가 브로커로부터 데이터를 받을 때 묶어서 데이터를 전송한다. 많은 양의 데이터를 송수신할 때 맺어지는 네트워크 비용은 무시할 수 없는 규모인데, Kafka는 더 적은 횟수의 연결로 동일 시간 내에 더 많은 데…","fields":{"slug":"/kafka/kafka_1/"},"frontmatter":{"date":"December 07, 2024","title":"1) Apache Kafka의 특징과 미래","category":"kafka","draft":false}}},{"node":{"excerpt":"CKA, CKAD 합격 후기 지난 2022년 7월부터 시작한 kubernetes 공부가 2024년 6~10월이 되서야 비로소 성과를 만들어 낼 수 있었다. 그 기간동안 지속적으로 공부한 기간도 있고, 잠시 쉰 기간도 있다 보니 첫 자격증 취득에도 꽤 많은 시간이 걸렸던 것 같다. 블로그에도 여러 자료를 올리기도 하고 했지만 중간에 중단했는데 그 때문에 더…","fields":{"slug":"/kubernetes/kubernetes_certificate/"},"frontmatter":{"date":"November 16, 2024","title":"CKA, CKAD 합격 후기","category":"kubernetes","draft":false}}},{"node":{"excerpt":"7.7 영구 볼륨(PV) 대규모 시스템이 모여 있는 클러스터 내에서 Pod가 생성될 때마다, Storage를 설정해줘야 한다. 모든 Pod에 일일히 설정하기는 너무 번거롭다. 쿠버네티스에는 중앙화된 거대한 pool의 스토리지를 생성하고, 각 유저들에게 조금씩 이를 쪼개어(carve out) 줄 수 있는데, 이러한 기능을 Persistent Volume이라…","fields":{"slug":"/kubernetes/kubernetes_7_3/"},"frontmatter":{"date":"February 05, 2024","title":"[쿠버네티스 완벽 가이드] 17. 컨피그 & 스토리지 API 카테고리 (3) - 영구 볼륨(PV), 영구 볼륨 클레임(PVC), Storage Class","category":"kubernetes","draft":false}}},{"node":{"excerpt":"7.5 영구 볼륨 클레임 리소스 영구 볼륨 클레임 리소스는 영구 볼륨을 사용하기 위한 리소스이다. 종류에는 볼륨, 영구 볼륨, 영구 볼륨 클레임이 있는데, 각각의 차이점은 다음과 같다. 볼륨: 미리 준비된 사용 가능 볼륨 등을 매니페스트에서 직접 지정하여 사용할 수 있게 하는 것이다. 설정된 볼륨의 사용은 가능하나, 신규 볼륨을 생성하거나 기존 볼륨을 삭…","fields":{"slug":"/kubernetes/kubernetes_7_2/"},"frontmatter":{"date":"February 05, 2024","title":"[쿠버네티스 완벽 가이드] 16. 컨피그 & 스토리지 API 카테고리 (2) - 볼륨 (Volume)","category":"kubernetes","draft":false}}},{"node":{"excerpt":"1. Flutter Firebase 연동 Flutter Provider 강의를 듣다가 Flutter 프로젝트 내에서 Firebase 연동하는 방법을 배우고 있었는데, Firebase 화면에서 Flutter 연동 아이콘이 있음을 확인하고 Flutter 프로젝트에 바로 연동할 수 있다는 것을 확인하였다. 1.1. Firebase 프로젝트 생성 먼저, Fire…","fields":{"slug":"/flutter/flutter_firebase/"},"frontmatter":{"date":"January 27, 2024","title":"[Flutter] Fluter-Firebase 연동 방법","category":"flutter","draft":false}}},{"node":{"excerpt":"1. ChangeNotifier를 이용한 action의 처리 이번에는 ChangeNotifier를 이용한 action의 처리 방법에 대해 알아보겠다. action의 종류에는 앞서 설명했던  뿐만 아니라, (팝업 표시),  등이 있다. action을 처리하는 프로세스 패턴은 다음과 같다. action을 수행하는 void 함수 생성  메소드 내 ChangeN…","fields":{"slug":"/flutter/flutter_7/"},"frontmatter":{"date":"January 21, 2024","title":"[Flutter] 07. ChangeNotifier를 이용한 action 처리","category":"flutter","draft":false}}},{"node":{"excerpt":"1. 개요 flutter를 사용하다 보면 자주 마주하게 되는 에러들이 있다. 이러한 에러들에 대한 정리와, 이를 어떻게 처리하면 좋을지에 대해 정리해보았다. 2. 에러들의 종류 2.1. ProviderNotFound Error 앞서 자주 보게되었던 ProviderNotFound에러이다. 이 에러가 발생하는 케이스는 몇 가지 있는데, 다음과 같다. 첫 번째…","fields":{"slug":"/flutter/flutter_6/"},"frontmatter":{"date":"January 21, 2024","title":"[Flutter] 06. Provider에서 자주 마주치게 되는 에러들","category":"flutter","draft":false}}},{"node":{"excerpt":"1. Proxy Provider Provider란 위젯에 Non-위젯 오브젝트를 제공하는 위젯이라고 할 수 있다. 만약, 한 Provider에서 다른 Provider의 값이 필요한 경우에는 어떻게 해야할까? 이 때는 를 사용할 수 있다. 는 다른 Provider들의 의존성을 가져와서 값을 만드는 Provider이다. ProxyProvider의 명세를 보면…","fields":{"slug":"/flutter/flutter_5/"},"frontmatter":{"date":"January 14, 2024","title":"[Flutter] 05. Proxy Provider","category":"flutter","draft":false}}},{"node":{"excerpt":"1. Provider Access Provider의 화면 전환은 Navigator 위젯을 통해 이루어진다. 몇 가지 용어 설명을 덪붙이자면, Route: Flutter에서 page, screen은 Route Object로 대표되며, Route Object는 Navigator 위젯으로 관리된다. Navigator: Navigator 위젯은 Route Obj…","fields":{"slug":"/flutter/flutter_4/"},"frontmatter":{"date":"January 14, 2024","title":"[Flutter] 04. Provider Access","category":"flutter","draft":false}}},{"node":{"excerpt":"1. Consumer flutter의 공식 홈페이지를 살펴보면 Consumer의 정의는 다음과 같다.  즉, Consumer를 상위 위젯으로 지정해놓으면 하위 위젯에서는 Provier.of나 extension 메소드 없이 바로 Provider로 정의된 인스턴스에 접근할 수 있다는 것이다. 여기서 BuilderContext와 Widget을 사용하지 않는다면…","fields":{"slug":"/flutter/flutter_3/"},"frontmatter":{"date":"January 08, 2024","title":"[Flutter] 03. Consumer, ProviderNotFoundException, Selector","category":"flutter","draft":false}}},{"node":{"excerpt":"1. FE 상태 관리의 필요성 FE 개발을 하다 보면 위와 같이 트리 구조의 위젯의 여러 부분에서 같은 값을 사용해야할 필요가 있다. 예를 들어 WidgetA의 카운터 값을 WidgetB에서도 사용하여 보여줄 필요가 있다는 말이다. 이를 위해서는, 두 위젯의 공통 부모인 WidgetC에서 counter 변수를 정의하고, 카운터 값을 변화시킬 수 있는 in…","fields":{"slug":"/flutter/flutter_2/"},"frontmatter":{"date":"January 07, 2024","title":"[Flutter] 02. 상태 관리 기법과 Provider","category":"flutter","draft":false}}},{"node":{"excerpt":"1. Flutter란? Flutter는 구글에서 개발한 dart 기반의 FE 개발 GUI SDK로, 하나의 코드 베이스로 플랫폼에 무관하게 모두 동작되는 앱을 위해 개발되었다. 즉 Android, Kotlin, Swift, Object-C와 같은 Native 앱 개발 언어들과 다르게 크로스 플랫폼을 지향한다고 볼 수 있다. 시장에서의 위치는 React N…","fields":{"slug":"/flutter/flutter_1/"},"frontmatter":{"date":"January 06, 2024","title":"[Flutter] 01. 왜 Flutter인가?","category":"flutter","draft":false}}},{"node":{"excerpt":"얼마 전 wsl2 커널을 잘못 건드렸다가 설치된 리눅스가 먹통이 되면서 재설치를 한 적이 있다. 재설치가 끝난 후 Virtual Box로 구성해놓은 k8s 클러스터 랩 환경이 박살나 있어서 다시 구축하려니 기존과 똑같이 하는데도 잘 안되는 부분이 있었다. 기존에는 CKA 강의를 보며 쉽게 구축했었는데, 다시 하려니 자꾸 뭔가가 안되는 것이다. 구체적으로는…","fields":{"slug":"/kubernetes/k8s_local_lab/"},"frontmatter":{"date":"August 21, 2023","title":"[k8s] Vagrant + VirtualBox + Kubeadm으로 Local Lab 환경 구축","category":"kubernetes","draft":false}}},{"node":{"excerpt":"RaspberryPi Pico는 라이베리파이 재단에서 소형 MCU 보드로, 기존 라즈베리파이가 MPU를 사용하여 OS를 올리는 방식과 달리 마이크로컨트롤러를 이용하였다. 또한, 자체 설계한 RP2040 프로세서로 작지만 강력한 성능을 보여주는 장치이다. 내가 프로젝트를 하면서 이 녀석을 사용하게 된 이유는 가성비가 엄청나다는 점이었다. 단순하게 가격 비교…","fields":{"slug":"/embedded/micropython_raspberrypi/"},"frontmatter":{"date":"August 14, 2023","title":"[MicroPython] RaspberryPi Pico에서 MicroPython 사용하기","category":"embedded","draft":false}}},{"node":{"excerpt":"최근 Raspberry Pi Pico W와 MicroPython을 사용한 작은 프로젝트를 하나 하고 있다. Thonny라는 IDE를 사용해서 Raspberry Pi Pico 의 파일을 옮기거나 빼올 수 있는데, 몇 개월 동안 씨름하고 나서야 외부 라이브러리를 받아오는 방법을 발견하였다. 직접  코드 파일을 넣어주고, 이 파일을 import하는 방법도 가능…","fields":{"slug":"/embedded/micropython_mip/"},"frontmatter":{"date":"August 14, 2023","title":"[MicroPython] mip를 통한 MicroPython 라이브러리 받기","category":"embedded","draft":false}}},{"node":{"excerpt":"1. JSONPath k8s에서는 각종 오브젝트의 세팅 정보를 YAML과 JSON 형태로 보여주는 경우가 많다. 대부분의 매니페스트 파일들이 YAML 형식이지만, YAML은 JSON으로도 쉽게 변경 가능하다. k8s 오브젝트를 운영하면서  명령어는 엄청 자주 사용하게 되는데, 특정 오브젝트의 핵심적인 정보들은  명령어를 사용하여 조회 가능하다. 하지만, …","fields":{"slug":"/kubernetes/k8s_jsonpath/"},"frontmatter":{"date":"August 11, 2023","title":"[k8s] Jsonpath","category":"kubernetes","draft":false}}},{"node":{"excerpt":"트랜잭션? ACID 원칙? Database에는 ACID 원칙이란 것이 있다. 데이터베이스 트랜잭션이 안전하게 수행되는 것을 보장하기 위한 원칙을 말한다. 트랜잭션이란 데이터베이스에서 작업의 단위를 말하며 한 트랜잭션 안에는 여러 쿼리가 동작할 수 있다. 위키에 등록된 데이터베이스 트랜잭션의 정의에는  라고 되어 있다. 트랜잭션에는 이러한 성질히 안전하게 …","fields":{"slug":"/db/acid/"},"frontmatter":{"date":"October 17, 2022","title":"[Database] ACID 원칙","category":"db","draft":false}}},{"node":{"excerpt":"7.1 컨피그 & 스토리지 API 카테고리 컨피그 & 스토리지 API 카테고리는 컨테이너에 대한 설정 파일, 패스워드 같은 기밀 정보를 추가하거나 영구 볼륨을 제공하기 위한 리소스이다. 시크릿 컨피그맵 영구 볼륨 클레임 7.2 환경 변수 사용 쿠버네티스에서 개별 컨테이너의 설정 내용은 환경 변수나 파일이 저장되어 있는 영역을 마운트하여 전달하는 것이 일반…","fields":{"slug":"/kubernetes/kubernetes_7_1/"},"frontmatter":{"date":"October 16, 2022","title":"[쿠버네티스 완벽 가이드] 15. 컨피그 & 스토리지 API 카테고리 (1) - 환경변수, 시크릿, 컨피그맵","category":"kubernetes","draft":false}}},{"node":{"excerpt":"6.8 헤드리스 서비스(None) 헤드리스(Headless) 서비스는 대상이 되는 개별 파드의 IP주소가 직접 반환되는 서비스이다. 지금까지 소개한 다른 서비스에서 부하 분산을 위해 제고오디는 엔드포인트는 가상 IP로 로드 밸런싱 동작을 하기 위해 여러 파드로 전송되는 IP 엔드포인트였다면, 헤드리스 서비스는 로드 밸런싱을 하기 위한 IP 주소는 제공되지…","fields":{"slug":"/kubernetes/kubernetes_6_3/"},"frontmatter":{"date":"September 18, 2022","title":"[쿠버네티스 완벽 가이드] 14. 서비스 API 카테고리 (3) - 헤드리스, ExternalName, None-Selector, 인그레스","category":"kubernetes","draft":false}}},{"node":{"excerpt":"6.5 NodePort NodePort 서비스는 ExternalIP와 비슷하다. 앞서 설명한 ExternalIP는 지정한 쿠버네티스 노드의 IP 주소:포트에서 수신한 트래픽을 컨테이너로 전송하는 형태로 외부와 통신할 수 있었다. 반면 NodePort는 모든 쿠버네티스 노드의 IP 주소:포트에서 수신한 트래픽을 컨테이너에 전송하는 형태로 외부와 통신할 수 …","fields":{"slug":"/kubernetes/kubernetes_6_2/"},"frontmatter":{"date":"September 12, 2022","title":"[쿠버네티스 완벽 가이드] 13. 서비스 API 카테고리 (2) - NodePort, LoadBalancer, 그 외 서비스","category":"kubernetes","draft":false}}},{"node":{"excerpt":"6.1 서비스 API 카테고리 서비스 API 카테고리는 클러스터상 컨테이너에 대한 엔드포인트를 제공하거나 레이블과 일치하는 컨테이너의 디스커버리에 사용되는 리소스이다. 내부적으로 사용되는 리소스를 제외하고 사용자가 직접 사용하는 것은 L4 로드밸런싱을 제공하는 서비스 리소스와 L7 로드밸런싱을 제공하는 인그레스 리소스가 있다. 또한, 서비스 리소스에는 제…","fields":{"slug":"/kubernetes/kubernetes_6_1/"},"frontmatter":{"date":"September 09, 2022","title":"[쿠버네티스 완벽 가이드] 12. 서비스 API 카테고리 (1) - 서비스 API 카테고리 개요 및 쿠버네티스 클러스터 네트워크와 서비스","category":"kubernetes","draft":false}}},{"node":{"excerpt":"1. 부하 분산 방법 대부분의 인터넷을 기반으로 오픈되어 있는 서비스들의 실운영 서버는 클라우드 환경이던 컨테이너 환경이던 트래픽을 견디게 하기 위해 여러 가지 방법들을 사용한다. 서비스의 부하를 견디게 하기 위한 방법에는 크게 두 가지가 있다. : Server 하드웨어의 스펙을 높이는 방법. : Server를 병렬적으로 여러 대로 늘려서 부하를 분산시키…","fields":{"slug":"/server/loadbalancer/"},"frontmatter":{"date":"September 09, 2022","title":"로드밸런서의 개념과 종류","category":"server","draft":false}}},{"node":{"excerpt":"5.7 잡 잡(Job)은 컨테이너를 사용하여 한 번만 실행되는 리소스다. 더 정확히는, N개의 병렬로 실행하면서 지정한 횟수의 컨테이너 실행(정상 종료)을 보장하는 리소스이다. 잡과 레플리카셋의 차이점은 ‘기동 중인 파드가 정지되는 것을 전제로 만들어졌는지’에 있다. 기본적으로 레플리카셋 등에서 파드의 정지는 예상치 못한 에러다. 반면 잡의 경우는 파드의…","fields":{"slug":"/kubernetes/kubernetes_5_5/"},"frontmatter":{"date":"September 04, 2022","title":"[쿠버네티스 완벽 가이드] 11. 워크로드 API 카테고리 (5) - 잡, 크론잡","category":"kubernetes","draft":false}}},{"node":{"excerpt":"5.5 데몬셋 데몬셋(DaemonSet)은 레플리카셋의 특수한 형태라고 할 수 있는 리소스이다. 레플리카셋은 각 쿠버네티스 노드에 총 N개의 파드를 노드의 리소스 상황에 맞게 배치한다. 그래서 각 노드의 파드 수가 동일하다고 할 수 없으며, 모든 노드에 반드시 배치된다고도 할 수 없다. 그러나 대몬셋은 각 노드에 파드를 하나씩 배치하는 리소스이다. 따라서…","fields":{"slug":"/kubernetes/kubernetes_5_4/"},"frontmatter":{"date":"August 28, 2022","title":"[쿠버네티스 완벽 가이드] 10. 워크로드 API 카테고리 (4) - 데몬셋, 스테이트풀셋","category":"kubernetes","draft":false}}},{"node":{"excerpt":"리눅스 서버에서 작업하다보면 특정 문서를 수정할 일이 생기게 된다. 보통 문서 전체를 수정하기보다는 특정 설정 값을 하나씩 설정하게 되는데 파일이 하나라면 vi 편집기로 수정이 가능하나, 파일이 여러 개인 경우, 한 파일 내에서 공통적으로 수정할 부분이 여러 군데인 경우 vi 편집기를 통한 수정은 번거로울 수 있다. 이럴 때 sed 명령어를 사용하면 쉽게…","fields":{"slug":"/linux/sed/"},"frontmatter":{"date":"August 28, 2022","title":"[Linux] sed 명령어","category":"linux","draft":false}}},{"node":{"excerpt":"5.4 디플로이먼트 디플로이먼트(Deployment)는 여러 레플리카셋을 관리하여 롤링 업데이트나 롤백 등을 구현하는 리소스이다. 디플로이먼트가 레플리카셋을 관리하고 레플리카셋이 파드를 관리하는 관계이다. 다음과 같이 동작한다. 신규 레플리카셋을 생성 신규 레플리카셋의 레플리카 수를 단계적으로 늘림 신규 레플리카셋의 레플리카 수를 단계적으로 줄임 (2,3…","fields":{"slug":"/kubernetes/kubernetes_5_3/"},"frontmatter":{"date":"August 28, 2022","title":"[쿠버네티스 완벽 가이드] 09. 워크로드 API 카테고리 (3) - 디플로이먼트","category":"kubernetes","draft":false}}},{"node":{"excerpt":"5.3 레플리카셋/레플리케이션 컨트롤러 레플리카셋(ReplicaSet) / 레플리케이션 컨트롤러(Replication Controller)는 파드의 레플리카를 생성하고 지정한 파드 수를 유지하는 리소스이다. 원래 파드의 레플리카를 생성하는 리소스의 이름은 레플리케이션 컨트롤러였는데, 시간이 지나 레플리카셋으로 이름이 변경되면서 일부 기능이 추가되었다. 5…","fields":{"slug":"/kubernetes/kubernetes_5_2/"},"frontmatter":{"date":"August 21, 2022","title":"[쿠버네티스 완벽 가이드] 08. 워크로드 API 카테고리 (2) - 레플리카셋/레플리케이션 컨트롤러","category":"kubernetes","draft":false}}},{"node":{"excerpt":"5.1 워크로드 API 카테고리란? 다음으로는 쿠버네티스 리소스 중 한 가지인 워크로드 API 카테고리의 리소스들에 대해 살펴보겠다. 워크로드 API 카테고리로 분류된 리소스는 클러스터에 컨테이너를 기동시키기 위해 사용되는 리소스이다. 내부에서 사용되는 리소스를 제외하고, 사용자가 직접 사용하는 리소스는 총 여덟가지 이다. 각 리소스는 파드를 최소 단위로…","fields":{"slug":"/kubernetes/kubernetes_5_1/"},"frontmatter":{"date":"August 13, 2022","title":"[쿠버네티스 완벽 가이드] 07. 워크로드 API 카테고리 (1) - 파드(Pod)","category":"kubernetes","draft":false}}},{"node":{"excerpt":"리눅스는 오픈소스 답게 엄청나게 많은 대분류와 종류들이 있다. 서버 작업할 때 리눅스의 정확한 버전을 알기 어려울 때가 있는데, 아래의 방법들 중 하나를 사용하면 된다.\n예시는 kubernetes nginx1.16 Offical 컨테이너 이미지에서 사용하였다. 1. OS 커널 정보 2. 리눅스 버전 확인 3. OS 비트 확인","fields":{"slug":"/linux/os/"},"frontmatter":{"date":"August 13, 2022","title":"[Linux] OS 확인 하는 법","category":"linux","draft":false}}},{"node":{"excerpt":"4.5.6 매니페스트 파일 설계 지금까지는 kubectl로 ‘한개 리소스가 정의된 한 개의 매니페스트 파일’을 적용하는 예들이었다면 실제로는 한 개의 매니페스트 파일에 여러 개의 리소스를 정의하거나 여러 매니페스트 파일을 동시에 적용할 수도 있다. 하나의 매니페스트 파일에 여러 리소스 정의 매니페스트 파일에는 여러 리소스를 한 개의 매니페스트 파일에 정의…","fields":{"slug":"/kubernetes/kubernetes_4_3/"},"frontmatter":{"date":"August 06, 2022","title":"[쿠버네티스 완벽 가이드] 06. API 리소스와 kubectl (3)","category":"kubernetes","draft":false}}},{"node":{"excerpt":"리소스의 종류 및 용도 노드 : 컨테이너가 배치되는 서버 네임스페이스 : 쿠버네티스 클러스터 안의 가상 클러스터. 파드 : 컨테이너의 집합 중 가장 작은 단위로 컨테이너 실행 방법을 정의한다. 레플리카 세트: 같은 스펙을 갖는 파드를 여러개 생성하고 관리하는 역할을 한다. 디플로이먼트 : 레플리카 세트의 리비전을 관리한다. 서비스 : 파드의 집합에 접근하…","fields":{"slug":"/kubernetes/kubernetes_terms/"},"frontmatter":{"date":"July 31, 2022","title":"쿠버네티스 용어 정리","category":"kubernetes","draft":false}}},{"node":{"excerpt":"매니페스트? 쿠버네티스에서는 클러스터 안에서 움직이는 컨테이너 애플리케이션이나 네트워크 설정, 배치 실행을 하는 잡 등과 같은 리소스를 작성한다. 이와 같은 구체적인 설정 정보를 파일로 관리하는데, 이것이 매니페스트 파일(manifest file)이다. 매니페스트 파일의 구조 매니페스트 파일은 쿠버네티스 리소스에 따라 작성 방법에 차이가 있을 순 있지만,…","fields":{"slug":"/kubernetes/kubernetes_manifest/"},"frontmatter":{"date":"July 31, 2022","title":"쿠버네티스의 매니페스트 파일","category":"kubernetes","draft":false}}},{"node":{"excerpt":"4.5 커맨드 라인 인터페이스(CLI) 도구 kubectl 쿠버네티스에서 클러스터 조작은 모두 쿠버네티스 마스터의 API를 통해 이루어진다. 직접 API를 호출해도 되지만, 커맨드 라인 인터페이스 도구 kubectl을 사용하여서도 조작이 가능하다. 4.5.1 인증 정보와 컨텍스트 (config) kubectl이 쿠버네티스 마스터와 통신할 때는 접속 대상의…","fields":{"slug":"/kubernetes/kubernetes_4_2/"},"frontmatter":{"date":"July 30, 2022","title":"[쿠버네티스 완벽 가이드] 05. API 리소스와 kubectl (2)","category":"kubernetes","draft":false}}},{"node":{"excerpt":"1 비밀키(Private key), 공개키(Public Key) 생성 외부 인증기관에서 인증서를 전달받지 않고, 내부적으로 사용할 RSA 키 페어가 필요하다면 아래 설명된 절차를 통해서 간단하게 키 페어를 만들어 낼 수 있다. 1.1 RSA key pair 생성 private.pem파일을 열어보면 -----BEGIN RSA PRIVATE KEY----- …","fields":{"slug":"/cert/openssl/"},"frontmatter":{"date":"July 30, 2022","title":"[Cert] openssl을 사용한 인증서 파일 생성","category":"cert","draft":false}}},{"node":{"excerpt":"openssl을 사용하여 인증서 파일을 생성하기 전에 각 파일 확장자 명이 궁금하여 찾아보다가 잘 정리된 자료가 있어 정리하였다. https를 지원하는 웹서버를 설정하거나 서명이나 암호화 관련된 개발을 하게되면 한번씩 인증서 관련된 파일을 다룰 일이 생기게 된다. 이때 항상 프로그램이나 라이브러리들이 지원하는 형식이 달라서 인증서 형식을 변환해아 하는데 …","fields":{"slug":"/cert/certificate_file/"},"frontmatter":{"date":"July 30, 2022","title":"[Cert] 인증서 파일 확장자 설명","category":"cert","draft":false}}},{"node":{"excerpt":"대학 때 컴퓨터 공학 과목을 들으며 한번 쯤은 외웠던 개념인데 몇 년이 지나다 보니 계속 까먹은 상태로 있어서… 한 번 정리해보자는 김에 작성하게 되었다. 보통 암호화, 복호화 시 사용하는 키가 같은지 다른지에 따라 개인키, 대칭키로 나뉜다. 용어가 여러 가지로 불리는데, 정리해보자면, 개인키 = 비밀키 = 대칭키 = 비공개키\n공개키 = 비대칭키 1. 개…","fields":{"slug":"/cert/key/"},"frontmatter":{"date":"July 30, 2022","title":"[Cert] 개인키, 공개키 키 종류 비교","category":"cert","draft":false}}},{"node":{"excerpt":"본 장에서부터는 본격적으로 쿠버네티스 실습 내용을 기록하였다.\n실습은 GKE(Google Kubernetes Engine)과 kind를 사용하였다. 4.1 실습 준비 본격적으로 컨테이너를 생성하기 전에 gcloud와 kind를 설치해두어야 한다.\nkind는 [쿠버네티스 완벽 가이드] 03. 쿠버네티스 환경에서 설치하는 방법을 안내하였다.\nGKE는 아래와 …","fields":{"slug":"/kubernetes/kubernetes_4_1/"},"frontmatter":{"date":"July 25, 2022","title":"[쿠버네티스 완벽 가이드] 04. API 리소스와 kubectl (1)","category":"kubernetes","draft":false}}},{"node":{"excerpt":"3. 쿠버네티스 환경의 종류 쿠버네티스는 여러 플랫폼 환경에서 클러스터를 구성할 수 있다. 크게는 다음과 같은 세 가지 방법을 고려할 수 있다. 로컬 쿠버네티스: 물리 머신 한 대에 구축하여 사용 쿠버네티스 구축 도구: 도구를 사용하여 온프레미스/클라우드에 클러스터를 구축하여 사용 관리형 쿠버네티스 서비스: 퍼블릭 클라우드의 관리형 서비스로 제공하는 클러…","fields":{"slug":"/kubernetes/kubernetes_3/"},"frontmatter":{"date":"July 23, 2022","title":"[쿠버네티스 완벽 가이드] 03. 쿠버네티스 환경","category":"kubernetes","draft":false}}},{"node":{"excerpt":"2. 쿠버네티스 소개 쿠버네티스란 컨테이너화된 애플리케이션의 배포, 확장 등을 관리하는 것을 자동화하기 위한 플랫폼(컨테이너 오케스트레이션 엔진)이다. 도커 자체만으로는 여러 호스트로 구성하거나 규모가 큰 서비스 환경에서 시스템을 구축하기 어려우므로, 이러한 오케스트레이션 플랫폼을 이용하는 것이 요즘의 추세이다. 컨테이너 오케스트레이션 엔진에는 도커 외에…","fields":{"slug":"/kubernetes/kubernetes_2/"},"frontmatter":{"date":"July 19, 2022","title":"[쿠버네티스 완벽 가이드] 02. 쿠버네티스 소개","category":"kubernetes","draft":false}}},{"node":{"excerpt":"쿠버네티스 관련 자격증인 CKA/CKAD에 대해 찾아보다가 이 책이 초보자부터 보기 좋다는 이야기를 들어서 구입하여 보게 되었다. 본 페이지에서는 이 책을 읽으며 새로 알게된 내용들을 정리하고자 작성하게 되었다. 1. 도커(Docker) 도커(Docker)는 컨테이너를 실행하기 위한 실행 환경(컨테이너 런타임) 및 툴킷을 의미한다. 쿠버네티스는 도커 외에…","fields":{"slug":"/kubernetes/kubernetes_1/"},"frontmatter":{"date":"July 18, 2022","title":"[쿠버네티스 완벽 가이드] 01. 도커","category":"kubernetes","draft":false}}},{"node":{"excerpt":"앞서 Go 기본 문법책을 살펴보면서 공부했던 동시성 개발에 대해 더 자세히 알고 싶어 동시성에 대해서만 다루고 있는 책을 살펴보았다.\n이라는 책인데, 동시성 개발의 역사부터 시작해서 Go언어에서 어떤 동시성 패턴을 제공하는지, 어떻게 더 편리하게 동시성을 관리할 수 있는지 패턴등을 알려주고 있다. 본 마크다운 문서에서는 책을 읽으면서 배운 용어들에 대해 …","fields":{"slug":"/Golang/concurrency_in_go_1/"},"frontmatter":{"date":"July 02, 2022","title":"[Go 동시성 프로그래밍] 01. 동시성 소개, 코드 모델링: 순차적인 프로세스 간의 통신","category":"Golang","draft":false}}},{"node":{"excerpt":"[Level 2] 기능 개발 기능 개발은 순차적으로 배포 가능한 기능들의 완료 시점을 계산하여 특정 일에 몇 개의 기능을 배포할 수 있는지 계산하는 문제였다. 문제 자체는 매우 쉬우나, 테스트 케이스 11번에서 함정이 있다. 배포 가능 기간을 계산하는 공식 중 과 같이 특정 케이스에서 결과가 2.XXXXX와 같은 값으로 나오는 경우가 있다. 이런 경우를 …","fields":{"slug":"/Algorithm/programmers_stack,queue/"},"frontmatter":{"date":"July 02, 2022","title":"[프로그래머스 연습문제] 스택, 큐","category":"Algorithm","draft":false}}},{"node":{"excerpt":"이번에는 다이나믹 프로그래밍 문제들을 풀어보았다.\nDP 알고리즘은 개념 자체가 생소하고 문제에 적용하기 어려워 그런지 LV3 이상 문제부터 있었다. [Level 3] N으로 표현 레벨 3인데 난이도가 생각보다 어려웠다… DP를 어떻게 적용할 수 있을까를 엄청 고민했다가 처음에 크게 실수 했다.\n처음 생각한 방안은 각 메모리에 메모리 인덱스를 만들 수 있는…","fields":{"slug":"/Algorithm/programmers_dynamic/"},"frontmatter":{"date":"June 11, 2022","title":"[프로그래머스 연습문제] Dynamic Programming","category":"Algorithm","draft":false}}},{"node":{"excerpt":"1. 운영체제에 종족적인 코드 처리 운영체제에 따라 코드가 다를 경우 다음과 같은 방식으로 처리할 수 있다. ₩runtime.GOOS`로 운영체제를 확인한 후 분기 처리. 해당 상수는 runtime 패키지에 정의되어 있는 상수이고, 운영체제를 확인할 때 사용한다. 운영체제에 따라 darwin, freebsd, linux, windows를 반환하며 이 값으…","fields":{"slug":"/Golang/package/"},"frontmatter":{"date":"June 11, 2022","title":"[Go 언어 문법 정리] 06. 패키지","category":"Golang","draft":false}}},{"node":{"excerpt":"1. 런타임 에러와 패닉 실행 중에 에러가 발생하면 Go 런타임은 패닉을 발생시킨다. 패닉이 발생하면 패닉 에러 메시지가 출력되고 프로그램이 종료된다.\n에러 상황이 심각해서 프로그램을 더 이상 실행할 수 없을 때는 panic() 함수를 사용해 강제로 패닉을 발생시키고 프로그램을 종료할 수 있다. 함수 안에서 panic()이 호출되면 현재 함수의 실행을 즉…","fields":{"slug":"/Golang/error/"},"frontmatter":{"date":"May 29, 2022","title":"[Go 언어 문법 정리] 05. 에러 처리","category":"Golang","draft":false}}},{"node":{"excerpt":"앞서 배운 병행 처리 코드를 다양하게 활용하여 네 가지 패턴을 만들어보았다. 활용 내용 타임아웃 시간이 오래 걸리는 작업에 타임아웃 처리하기 공유 메모리 채널을 사용하여 여러 고루틴의 공유 메모리 접근 제어하기 파이프라인 여러 고루틴을 파이프라인 형태로 연결하기 맵 리듀스 고루틴을 사용하여 맵리듀스 패턴 구현하기 1. 타임아웃 시간이 오래 걸리는 작업에 …","fields":{"slug":"/Golang/concurrency_3/"},"frontmatter":{"date":"April 16, 2022","title":"[Go 언어 문법 정리] 04. 병행 처리 (3) 병행 처리 활용","category":"Golang","draft":false}}},{"node":{"excerpt":"1. 저수준 제어 Go에는 고루틴과 채널 외에도 병행 프로그래밍을 위한 저수준 제어 기능이 있다. 패키지 내용 sync mutex로 공유 메모리 제어 sync/atomic 원자성을 보장 (add, compare, swap) 1.1 sync.Mutex 뮤텍스(Mutex)는 여러 고루틴에서 공유하는 데이터를 보호해야 할 때 사용한다. func (m *Mute…","fields":{"slug":"/Golang/concurrency_2/"},"frontmatter":{"date":"April 16, 2022","title":"[Go 언어 문법 정리] 04. 병행 처리 (2) 저수준 제어","category":"Golang","draft":false}}},{"node":{"excerpt":"1. 고루틴(goroutine) 이번에는 Go언어에서 지원하는 몇 가지 병행 처리 기법에 대해서 볼 예정이다.\nGo언어의 가장 큰 특징 중 하나인 goroutine이 바로 그러한 기능인데,\n은 Go 프로그램 안에서 동시에 독립적으로 실행되는 흐름의 단위로, 스레드와 비슷한 개념이다.\n하지만, 스레드와 달리 고루틴은 수 킬로바이트 정도의 아주 작은 리소스에…","fields":{"slug":"/Golang/concurrency_1/"},"frontmatter":{"date":"April 02, 2022","title":"[Go 언어 문법 정리] 04. 병행 처리 (1) 고루틴과 채널","category":"Golang","draft":false}}},{"node":{"excerpt":"Go 언어 웹 프로그래밍 철저 입문 책으로 공부하면서 개인적으로 알아두면 좋은 문법 몇 가지를 정리해보려 한다.\n매우 기초적인 문법까지는 너무 양이 많을 것 같아 제외하였고, 내 기준 신기한 문법만 정리해보았다. 1. 레이블 레이블이란 c 언어의 레이블과 유사하면서도 조금 다르게도 사용 가능한 문법이다.\n아래 두 예시와 같이 대문자 + 콜론(:)의 형태로…","fields":{"slug":"/Golang/basic_grammer/"},"frontmatter":{"date":"March 01, 2022","title":"[Go 언어 문법 정리] 01. 기초 문법","category":"Golang","draft":false}}},{"node":{"excerpt":"오랜만에 DFS, BFS 문제들을 풀어보았다.\n주로 DFS 기법을 자주 사용하여 풀었다. [Level 2] 타겟 넘버 DFS, BFS 문제 중 간단한 편에 속하는 문제이다. Queue를 사용하였고, 노드별 가지가 2개밖에 되지 않아 간단하게 구현 가능하다.\n다만, 기존에 C++로 문제를 제출한 이력이 있어서 Go언어로 다시 풀어보았다. Go언어에는 Que…","fields":{"slug":"/Algorithm/programmers_dfs,bfs/"},"frontmatter":{"date":"March 01, 2022","title":"[프로그래머스 연습문제] BFS, DFS","category":"Algorithm","draft":false}}},{"node":{"excerpt":"JWT Token과 PASETO에 대한 비교 웹 개발 공부를 하던 중 JWT Token에 대응되는 PASETO 대해 알게 되어 관련 내용을 정리해보고자 한다. 1. JWT Token 이란? JWT Token은 웹 개발자에게는 매우 익숙한 개념이다. 사용자의 로그인에 대한 인가를 위해 Access, Refresh 토큰 등을 발행하여 브라우저에서는 해당 정보…","fields":{"slug":"/http/jwt&paesto/"},"frontmatter":{"date":"October 25, 2021","title":"[HTTP] JWT Token과 PASETO","category":"http","draft":false}}},{"node":{"excerpt":"크롬 브라우저의 쿠키 정책과 SameSite 작년 중 고객 정보 관련 업무를 처리하다 크롬 브라우저의 정책 변경으로 인해 곤혹을 치른적이 있다.\n결론부터 말하자면 SameSite의 Default 설정이 변경된 것인데, 이 변경이 일부 환경에서 서비스 장애를 초래한 것이다.\n간단히 말하자면, SameSite 기본 설정의 변경으로 크로스 도메인간 http 메…","fields":{"slug":"/http/samesite/"},"frontmatter":{"date":"October 04, 2021","title":"[HTTP] 크롬 브라우저의 쿠키 정책과 SameSite","category":"http","draft":false}}},{"node":{"excerpt":"코테 연습할겸해서 풀었던 해시 문제들에 대한 풀이를 올려보았다. [Level 1] 완주하지 못한 선수 매우 간단한 문제로, 참가자와 완료한 선수들 명단이 있는데, 이중 완료하지 못한 선수 이름을 리턴하기만 하면 된다. 해시 맵에 묶여있어서 map을 글대로 사용해서 아래와 같이 작성했다. 가장 효율적인 풀이를 보니 그냥 두 vector를 정렬해서 차례로 비…","fields":{"slug":"/Algorithm/programmers_hash/"},"frontmatter":{"date":"October 04, 2021","title":"[프로그래머스 연습문제] 해시","category":"Algorithm","draft":false}}},{"node":{"excerpt":"이번에는 생성한 gatsby 프로젝트를 Netlify를 사용해 배포하는 법에 대해 적어보겠다. 설치 과정이 좀 고됬지만 배포는 그보다는 훨씬 간단하다. Netlify라는 정적 웹사이트 배포 도구가 있어 별도 도메인을 빌려야할 필요도 없고, github 계정만 있으면 된다. 배포 방법 1. git repository 생성 Netlify에 연동하기 전에, g…","fields":{"slug":"/gatsby/gatsby_deploy/"},"frontmatter":{"date":"September 25, 2021","title":"[Gatsby Blog 만들기 - 2] Gastby Blog 배포 (gatsby-starter-bee)","category":"gatsby","draft":false}}},{"node":{"excerpt":"오랫만에 다시 Gatsby 블로그를 개설했다. 너무 간만인지 개삽질을 거듭해서 아래와 같이 정리하게 되었다. Windows WSL2 기반으로 작성했으며, WSL2 설치는 아래 Blog를 참조하였다. 설치 방법 😎 1. nvm 설치 가장 먼저, NodeJS를 설치했다. 다만, 그 전에 WSL2 설치하니 NodeJS가 기존 system 버전으로 잡혀있어서 n…","fields":{"slug":"/gatsby/gatsby_start/"},"frontmatter":{"date":"September 25, 2021","title":"[Gatsby Blog 만들기 - 1] Gastby Blog 설치 (gatsby-starter-bee)","category":"gatsby","draft":false}}}]}},"pageContext":{}},"staticQueryHashes":["3128451518","643154061"],"slicesMap":{}}